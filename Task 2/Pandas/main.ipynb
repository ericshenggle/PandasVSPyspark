{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description:\n",
    "\n",
    "The dataset is comprised of tab-separated files with phrases from the IMDB Movie Ratings. The train/test split has been preserved for the purposes of benchmarking, but the sentences have been shuffled from their original order. Each Sentence has been parsed into many phrases by the Stanford parser. Each phrase has a PhraseId. Each sentence has a SentenceId. Phrases that are repeated (such as short/common words) are only included once in the data.\n",
    "\n",
    "train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.\n",
    "test.tsv contains just phrases. You must assign a sentiment label to each phrase.\n",
    "The sentiment labels are:\n",
    "\n",
    "0 - negative\n",
    "1 - positive\n",
    "\n",
    "### Objective:\n",
    "- Understand the Dataset & cleanup (if required).\n",
    "- Build classification models to predict the ratings of the movie.\n",
    "- Compare the evaluation metrics of vaious classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>1. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T19:38:15.780569Z",
     "iopub.status.busy": "2022-04-19T19:38:15.780193Z",
     "iopub.status.idle": "2022-04-19T19:38:17.736209Z",
     "shell.execute_reply": "2022-04-19T19:38:17.735429Z",
     "shell.execute_reply.started": "2022-04-19T19:38:15.780479Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Importing the necessary librarires\n",
    "\n",
    "import os\n",
    "import math\n",
    "import nltk\n",
    "import scipy\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, \\\n",
    "roc_auc_score, roc_curve, precision_score, recall_score\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:46:27.80843Z",
     "iopub.status.busy": "2022-01-19T11:46:27.808126Z",
     "iopub.status.idle": "2022-01-19T11:46:28.401063Z",
     "shell.execute_reply": "2022-01-19T11:46:28.398188Z",
     "shell.execute_reply.started": "2022-01-19T11:46:27.808387Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Importing the dataset\n",
    "\n",
    "df = pd.read_csv('../input/imdb-movie-ratings-sentiment-analysis/movie.csv', header=0)\n",
    "target = 'label'\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "original_df = df.copy(deep=True)\n",
    "\n",
    "print('\\n\\033[1mInference:\\033[0m The Datset consists of {} features & {} samples.'.format(df.shape[1], df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** The stats seem to be fine, let us gain more undestanding by visualising the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:46:28.454014Z",
     "iopub.status.busy": "2022-01-19T11:46:28.453655Z",
     "iopub.status.idle": "2022-01-19T11:46:28.469885Z",
     "shell.execute_reply": "2022-01-19T11:46:28.468853Z",
     "shell.execute_reply.started": "2022-01-19T11:46:28.453966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Check for empty elements\n",
    "\n",
    "print(df.isnull().sum())\n",
    "print('\\n\\033[1mInference:\\033[0m The dataset doesn\\'t have any null elements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:46:28.472212Z",
     "iopub.status.busy": "2022-01-19T11:46:28.471343Z",
     "iopub.status.idle": "2022-01-19T11:46:28.636744Z",
     "shell.execute_reply": "2022-01-19T11:46:28.636108Z",
     "shell.execute_reply.started": "2022-01-19T11:46:28.47216Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Removal of any Duplicate rows (if any)\n",
    "\n",
    "counter = 0\n",
    "r,c = original_df.shape\n",
    "\n",
    "df1 = df.drop_duplicates()\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# if df1.shape==(r,c):\n",
    "#     print('\\n\\033[1mInference:\\033[0m The dataset doesn\\'t have any duplicates')\n",
    "# else:\n",
    "#     print(f'\\n\\033[1mInference:\\033[0m Number of duplicates dropped/fixed ---> {r-df1.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T11:46:28.638463Z",
     "iopub.status.busy": "2022-01-19T11:46:28.63767Z",
     "iopub.status.idle": "2022-01-19T12:13:20.524205Z",
     "shell.execute_reply": "2022-01-19T12:13:20.523369Z",
     "shell.execute_reply.started": "2022-01-19T11:46:28.638423Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Filtering the text\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "df = df1.copy()\n",
    "\n",
    "def preprocessor(text):\n",
    "    text = text.lower()\n",
    "    text = ''.join([i for i in text if i in string.ascii_lowercase+' '])\n",
    "    text = ' '.join([PorterStemmer().stem(word) for word in text.split()])\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text\n",
    "\n",
    "#with Pool(4) as p:\n",
    "#    df['text'] = list(tqdm(p.imap(preprocessor, range(df.shape[0]))))\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    df.loc[i,'text'] = preprocessor(df['text'][i])\n",
    "\n",
    "#from tqdm.contrib.concurrent import process_map \n",
    "\n",
    "#df['text'] = process_map(tqdm(preprocessor, df['text'], max_workers=8))\n",
    "\n",
    "#for i in tqdm()\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inference:** The text is now clean up with the removal of all punctuations, stopwords & stemming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:13:20.526492Z",
     "iopub.status.busy": "2022-01-19T12:13:20.525622Z",
     "iopub.status.idle": "2022-01-19T12:15:45.098215Z",
     "shell.execute_reply": "2022-01-19T12:15:45.097614Z",
     "shell.execute_reply.started": "2022-01-19T12:13:20.526445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "porter=PorterStemmer()\n",
    "def tokenizer(text):\n",
    "        return text.split()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "tfidf=TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None,tokenizer=tokenizer_porter,use_idf=True,norm='l2',smooth_idf=True)\n",
    "y=df.label.values\n",
    "x=tfidf.fit_transform(df.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> 3. Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:17:10.663543Z",
     "iopub.status.busy": "2022-01-19T12:17:10.663124Z",
     "iopub.status.idle": "2022-01-19T12:17:10.693184Z",
     "shell.execute_reply": "2022-01-19T12:17:10.692358Z",
     "shell.execute_reply.started": "2022-01-19T12:17:10.663503Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Splitting the data intro training & testing sets\n",
    "\n",
    "X = df.drop([target],axis=1)\n",
    "Y = df[target]\n",
    "Train_X, Test_X, Train_Y, Test_Y = train_test_split(x, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Original set  ---> ',X.shape,Y.shape,'\\nTraining set  ---> ',Train_X.shape,Train_Y.shape,'\\nTesting set   ---> ', Test_X.shape,'', Test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:17:10.694901Z",
     "iopub.status.busy": "2022-01-19T12:17:10.694487Z",
     "iopub.status.idle": "2022-01-19T12:17:10.710781Z",
     "shell.execute_reply": "2022-01-19T12:17:10.709887Z",
     "shell.execute_reply.started": "2022-01-19T12:17:10.694869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Let us create first create a table to store the results of various models \n",
    "\n",
    "Evaluation_Results = pd.DataFrame(np.zeros((4,5)), columns=['Accuracy', 'Precision','Recall','F1-score','AUC-ROC score'])\n",
    "Evaluation_Results.index=['Logistic Regression (LR)','Decision Tree Classifier (DT)','Random Forest Classifier (RF)','Naïve Bayes Classifier (NB)']\n",
    "Evaluation_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:17:10.713434Z",
     "iopub.status.busy": "2022-01-19T12:17:10.712671Z",
     "iopub.status.idle": "2022-01-19T12:17:10.728331Z",
     "shell.execute_reply": "2022-01-19T12:17:10.727484Z",
     "shell.execute_reply.started": "2022-01-19T12:17:10.713378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Let us define functions to summarise the Prediction's scores .\n",
    "\n",
    "#Classification Summary Function\n",
    "def Classification_Summary(pred,pred_prob,i):\n",
    "    Evaluation_Results.iloc[i]['Accuracy']=round(accuracy_score(Test_Y, pred),3)*100   \n",
    "    Evaluation_Results.iloc[i]['Precision']=round(precision_score(Test_Y, pred),3)*100 #, average='weighted'\n",
    "    Evaluation_Results.iloc[i]['Recall']=round(recall_score(Test_Y, pred),3)*100 #, average='weighted'\n",
    "    Evaluation_Results.iloc[i]['F1-score']=round(f1_score(Test_Y, pred),3)*100 #, average='weighted'\n",
    "    Evaluation_Results.iloc[i]['AUC-ROC score']=round(roc_auc_score(Test_Y, pred),3)*100 #, multi_class='ovr'\n",
    "    print('{}{}\\033[1m Evaluating {} \\033[0m{}{}\\n'.format('<'*3,'-'*35,Evaluation_Results.index[i], '-'*35,'>'*3))\n",
    "    print('Accuracy = {}%'.format(round(accuracy_score(Test_Y, pred),3)*100))\n",
    "    print('F1 Score = {}%'.format(round(f1_score(Test_Y, pred),3)*100)) #, average='weighted'\n",
    "    print('\\n \\033[1mConfusiton Matrix:\\033[0m\\n',confusion_matrix(Test_Y, pred))\n",
    "    print('\\n\\033[1mClassification Report:\\033[0m\\n',classification_report(Test_Y, pred))\n",
    "    \n",
    "\n",
    "#Visualising Function\n",
    "def AUC_ROC_plot(Test_Y, pred):    \n",
    "    ref = [0 for _ in range(len(Test_Y))]\n",
    "    ref_auc = roc_auc_score(Test_Y, ref)\n",
    "    lr_auc = roc_auc_score(Test_Y, pred)\n",
    "\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(Test_Y, ref)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(Test_Y, pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:19:48.095826Z",
     "iopub.status.busy": "2022-01-19T12:19:48.095541Z",
     "iopub.status.idle": "2022-01-19T12:19:53.736902Z",
     "shell.execute_reply": "2022-01-19T12:19:53.73602Z",
     "shell.execute_reply.started": "2022-01-19T12:19:48.095793Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building Logistic Regression Classifier\n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "LR = LR_model.fit(Train_X, Train_Y)\n",
    "pred = LR.predict(Test_X)\n",
    "pred_prob = LR.predict_proba(Test_X)\n",
    "Classification_Summary(pred,pred_prob,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Decisoin Tree Classfier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:19:53.739441Z",
     "iopub.status.busy": "2022-01-19T12:19:53.738953Z",
     "iopub.status.idle": "2022-01-19T12:20:59.971543Z",
     "shell.execute_reply": "2022-01-19T12:20:59.970672Z",
     "shell.execute_reply.started": "2022-01-19T12:19:53.739389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building Decision Tree Classifier\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "DT = DT_model.fit(Train_X, Train_Y)\n",
    "pred = DT.predict(Test_X)\n",
    "pred_prob = DT.predict_proba(Test_X)\n",
    "Classification_Summary(pred,pred_prob,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Random Forest Classfier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:20:59.973004Z",
     "iopub.status.busy": "2022-01-19T12:20:59.972771Z",
     "iopub.status.idle": "2022-01-19T12:23:30.279675Z",
     "shell.execute_reply": "2022-01-19T12:23:30.278763Z",
     "shell.execute_reply.started": "2022-01-19T12:20:59.972976Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building Random Forest Classifier\n",
    "\n",
    "RF_model = RandomForestClassifier()\n",
    "RF = RF_model.fit(Train_X, Train_Y)\n",
    "pred = RF.predict(Test_X)\n",
    "pred_prob = RF.predict_proba(Test_X)\n",
    "Classification_Summary(pred,pred_prob,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Naive Bayes Classfier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-19T12:23:30.282556Z",
     "iopub.status.busy": "2022-01-19T12:23:30.282158Z",
     "iopub.status.idle": "2022-01-19T12:23:30.663066Z",
     "shell.execute_reply": "2022-01-19T12:23:30.662263Z",
     "shell.execute_reply.started": "2022-01-19T12:23:30.282507Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Building Naive Bayes Classifier\n",
    "\n",
    "NB_model = BernoulliNB()\n",
    "NB = NB_model.fit(Train_X, Train_Y)\n",
    "pred = NB.predict(Test_X)\n",
    "pred_prob = NB.predict_proba(Test_X)\n",
    "Classification_Summary(pred,pred_prob,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
